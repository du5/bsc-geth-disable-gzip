--- bsc/node/rpcstack.go	2023-11-14 14:40:40
+++ bsc/node/rpcstack.go	2023-11-14 14:40:34
@@ -17,14 +17,11 @@
 package node

 import (
-	"compress/gzip"
 	"context"
 	"fmt"
-	"io"
 	"net"
 	"net/http"
 	"sort"
-	"strconv"
 	"strings"
 	"sync"
 	"sync/atomic"
@@ -393,7 +390,7 @@
 	if len(jwtSecret) != 0 {
 		handler = newJWTHandler(jwtSecret, handler)
 	}
-	return newGzipHandler(handler)
+	return handler
 }

 // NewWSHandlerStack returns a wrapped ws-related handler.
@@ -462,120 +459,8 @@
 		return
 	}
 	http.Error(w, "invalid host specified", http.StatusForbidden)
-}
-
-var gzPool = sync.Pool{
-	New: func() interface{} {
-		w := gzip.NewWriter(io.Discard)
-		return w
-	},
-}
-
-type gzipResponseWriter struct {
-	resp http.ResponseWriter
-
-	gz            *gzip.Writer
-	contentLength uint64 // total length of the uncompressed response
-	written       uint64 // amount of written bytes from the uncompressed response
-	hasLength     bool   // true if uncompressed response had Content-Length
-	inited        bool   // true after init was called for the first time
-}
-
-// init runs just before response headers are written. Among other things, this function
-// also decides whether compression will be applied at all.
-func (w *gzipResponseWriter) init() {
-	if w.inited {
-		return
-	}
-	w.inited = true
-
-	hdr := w.resp.Header()
-	length := hdr.Get("content-length")
-	if len(length) > 0 {
-		if n, err := strconv.ParseUint(length, 10, 64); err != nil {
-			w.hasLength = true
-			w.contentLength = n
-		}
-	}
-
-	// Setting Transfer-Encoding to "identity" explicitly disables compression. net/http
-	// also recognizes this header value and uses it to disable "chunked" transfer
-	// encoding, trimming the header from the response. This means downstream handlers can
-	// set this without harm, even if they aren't wrapped by newGzipHandler.
-	//
-	// In go-ethereum, we use this signal to disable compression for certain error
-	// responses which are flushed out close to the write deadline of the response. For
-	// these cases, we want to avoid chunked transfer encoding and compression because
-	// they require additional output that may not get written in time.
-	passthrough := hdr.Get("transfer-encoding") == "identity"
-	if !passthrough {
-		w.gz = gzPool.Get().(*gzip.Writer)
-		w.gz.Reset(w.resp)
-		hdr.Del("content-length")
-		hdr.Set("content-encoding", "gzip")
-	}
 }

-func (w *gzipResponseWriter) Header() http.Header {
-	return w.resp.Header()
-}
-
-func (w *gzipResponseWriter) WriteHeader(status int) {
-	w.init()
-	w.resp.WriteHeader(status)
-}
-
-func (w *gzipResponseWriter) Write(b []byte) (int, error) {
-	w.init()
-
-	if w.gz == nil {
-		// Compression is disabled.
-		return w.resp.Write(b)
-	}
-
-	n, err := w.gz.Write(b)
-	w.written += uint64(n)
-	if w.hasLength && w.written >= w.contentLength {
-		// The HTTP handler has finished writing the entire uncompressed response. Close
-		// the gzip stream to ensure the footer will be seen by the client in case the
-		// response is flushed after this call to write.
-		err = w.gz.Close()
-	}
-	return n, err
-}
-
-func (w *gzipResponseWriter) Flush() {
-	if w.gz != nil {
-		w.gz.Flush()
-	}
-	if f, ok := w.resp.(http.Flusher); ok {
-		f.Flush()
-	}
-}
-
-func (w *gzipResponseWriter) close() {
-	if w.gz == nil {
-		return
-	}
-	w.gz.Close()
-	gzPool.Put(w.gz)
-	w.gz = nil
-}
-
-func newGzipHandler(next http.Handler) http.Handler {
-	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
-		if !strings.Contains(r.Header.Get("Accept-Encoding"), "gzip") {
-			next.ServeHTTP(w, r)
-			return
-		}
-
-		wrapper := &gzipResponseWriter{resp: w}
-		defer wrapper.close()
-
-		next.ServeHTTP(wrapper, r)
-	})
-}
-
 type ipcServer struct {
 	log      log.Logger
 	endpoint string
